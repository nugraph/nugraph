{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81a2132-ba1f-4c7d-9b28-19b6577300bc",
   "metadata": {},
   "source": [
    "### Set autoreloading\n",
    "This extension will automatically update with any changes to packages in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db0367-043e-48a0-bf50-0867d505b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dcd317-00bc-4d1b-bcc4-900e5da8fd12",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "We'll need the `pytorch_lightning` and `nugraph` packages imported in order to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de9ffe-2d9f-48ee-b8c3-533ba9b7bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nugraph as ng\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import torchmetrics as tm\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcc164-dce4-4724-9003-5cff78b0081a",
   "metadata": {},
   "source": [
    "### Set default plotting options\n",
    "\n",
    "Define a dictionary containing all standard plotting options that we want to set for all the plots we draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b78655-7e40-47d0-8b04-f98df02b3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {\n",
    "    'layout_width': 800,\n",
    "    'layout_height': 450,\n",
    "    'layout_margin_b': 20,\n",
    "    'layout_margin_t': 20,\n",
    "    'layout_margin_r': 20,\n",
    "    'layout_margin_l': 20,\n",
    "    'layout_xaxis_title_font_size': 24,\n",
    "    'layout_xaxis_tickfont_size': 20,\n",
    "    'layout_yaxis_title_font_size': 24,\n",
    "    'layout_yaxis_tickfont_size': 20,\n",
    "    'layout_legend_font_size': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117354c7-1d2f-4e9d-ac53-ef62689609fd",
   "metadata": {},
   "source": [
    "### Define label score metrics\n",
    "\n",
    "Define a torchmetrics class to make true & false score distributions for each semantic label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6821a26-6257-4f9a-a927-a7b4a2d1a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score(tm.Metric):\n",
    "    def __init__(self,\n",
    "                 num_classes: int,\n",
    "                 bins: int = 20,\n",
    "                 range: tuple[float] = (0,1),\n",
    "                 ignore_index: int = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bins = bins\n",
    "        self.range = range\n",
    "        self.ignore_index = ignore_index\n",
    "        \n",
    "        self.add_state('true', default=torch.zeros(num_classes, bins), dist_reduce_fx = 'sum')\n",
    "        self.add_state('false', default=torch.zeros(num_classes, bins), dist_reduce_fx = 'sum')\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "\n",
    "        # check that number of classes is correct\n",
    "        num_classes = preds.size(1)\n",
    "        assert num_classes == self.true.size(0)\n",
    "\n",
    "        # loop over labels\n",
    "        filter = (target != self.ignore_index)\n",
    "        for label in range(num_classes):\n",
    "            mask = filter & (target == label)\n",
    "            hist, bin_edges = preds[mask, label].histogram(bins=self.bins,\n",
    "                                                           range=self.range)\n",
    "            self.true[label] += hist\n",
    "            mask = filter & (target != label)\n",
    "            hist, bin_edges = preds[mask, label].histogram(bins=self.bins,\n",
    "                                                           range=self.range)\n",
    "            self.false[label] += hist\n",
    "        \n",
    "    def compute(self):\n",
    "        true = self.true / self.true.sum(dim=1)[:,None]\n",
    "        false = self.false / self.false.sum(dim=1)[:,None]\n",
    "        return true, false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463a630-07ef-42ba-bcea-37c70133512b",
   "metadata": {},
   "source": [
    "### Configure data module\n",
    "Declare a data module. Depending on where you're working, you should edit the data path below to point to a valid data location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32ec68-0b7c-4566-a1d8-fa734ceb2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "nudata = ng.data.H5DataModule(data_path='/raid/uboone/NuGraph2/NG2-paper.gnn.h5', batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d8df0-1cfe-47d9-88d3-6be09992d4ad",
   "metadata": {},
   "source": [
    "### Configure network\n",
    "In order to test a trained model, we instantiate it using a checkpoint file. These are produced during training, so if you've trained a model, there should be an associated checkpoint in your output directory that you can pass here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05ed20-20e8-46f8-89d4-1657e13ee52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ng.models.NuGraph2.load_from_checkpoint('/raid/uboone/NuGraph2/NG2-paper.ckpt', map_location='cpu')\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9cfaaa-f81c-465e-8206-603ca095e26d",
   "metadata": {},
   "source": [
    "### Declare trainer and run testing\n",
    "First we set the training device. In the instance that we're in a multi-GPU environment, the code will automatically select the GPU with the most available memory; otherwise, it defaults to CPU training. We then instantiate a PyTorch Lightning trainer that we'll use for testing, and then run the testing stage, which iterates over all batches in the test dataset and prints performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5712a1-150c-4f09-9c45-b6bd65470ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator, devices = ng.util.configure_device()\n",
    "trainer = pl.Trainer(accelerator=accelerator,\n",
    "                     devices=devices,\n",
    "                     logger=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f688b877-9b8b-4105-b8eb-4129b34bcdd4",
   "metadata": {},
   "source": [
    "### Calculate testing metrics\n",
    "\n",
    "Loop over each batch and produce testing plots: score distributions and ROC curves per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1a6df-6171-4f2b-a9b7-57c4790b03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(nudata.semantic_classes)\n",
    "\n",
    "score = Score(num_classes=num_classes, ignore_index=-1)\n",
    "roc_filter = tm.classification.BinaryROC(\n",
    "    thresholds=1000,\n",
    ")\n",
    "roc_semantic = tm.classification.MulticlassROC(\n",
    "    num_classes=num_classes,\n",
    "    thresholds=1000,\n",
    "    ignore_index=-1,\n",
    ")\n",
    "\n",
    "batches = trainer.predict(model, nudata.test_dataloader())\n",
    "\n",
    "for batch in tqdm.tqdm(batches):\n",
    "    for p in nudata.planes:\n",
    "        score.update(batch[p].x_semantic, batch[p].y_semantic)\n",
    "        roc_filter.update(batch[p].x_filter, batch[p].y_semantic!=-1)\n",
    "        roc_semantic.update(batch[p].x_semantic, batch[p].y_semantic)\n",
    "\n",
    "true, false = score.compute()\n",
    "fpr_filter, tpr_filter, thresholds = roc_filter.compute()\n",
    "fpr_semantic, tpr_semantic, thresholds = roc_semantic.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768aa808-de51-4bc9-a374-640eb730e12c",
   "metadata": {},
   "source": [
    "### Filter ROC curve\n",
    "\n",
    "Draw ROC curve for filter decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58d61e-c13b-4337-8cba-580811194059",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    layout_xaxis_title='False positive rate',\n",
    "    layout_xaxis_range=(0,0.15),\n",
    "    layout_yaxis_title='True positive rate',\n",
    "    layout_yaxis_range=(0.7,1),\n",
    "    layout_legend_xanchor='right',\n",
    "    layout_legend_x=0.9,\n",
    "    layout_legend_yanchor='bottom',\n",
    "    layout_legend_y=0.1,\n",
    "    **style,\n",
    ")\n",
    "fig.add_scatter(x=fpr_filter, y=tpr_filter)\n",
    "fig.write_image('plots/roc-filter.pdf')\n",
    "fig.write_image('plots/roc-filter.png')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ea97b-3ac1-4719-a777-caf37fd384b1",
   "metadata": {},
   "source": [
    "### Plot semantic ROC curves\n",
    "\n",
    "Draw semantic ROC curves for each semantic class on the same axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ad6d6-cfef-478b-a325-923eeb4493bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    layout_xaxis_title='False positive rate',\n",
    "    layout_xaxis_range=(0,0.15),\n",
    "    layout_yaxis_title='True positive rate',\n",
    "    layout_yaxis_range=(0.7,1),\n",
    "    layout_legend_xanchor='right',\n",
    "    layout_legend_x=0.9,\n",
    "    layout_legend_yanchor='bottom',\n",
    "    layout_legend_y=0.1,\n",
    "    **style,\n",
    ")\n",
    "for label, name in enumerate(nudata.semantic_classes):\n",
    "    fig.add_scatter(x=fpr_semantic[label], y=tpr_semantic[label], name=name)\n",
    "fig.write_image('plots/roc-semantic.pdf')\n",
    "fig.write_image('plots/roc-semantic.png')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9268781d-5027-4945-ae59-4c0f2f72f162",
   "metadata": {},
   "source": [
    "### Plot score distributions\n",
    "\n",
    "For true and false predictions, draw the score distributions for each semantic class on the same axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfb2f6-d979-4880-955c-1ec8257322bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = torch.linspace(0, 1, 21)\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "for name, y in (('true',true),('false',false)):\n",
    "\n",
    "    fig = go.Figure(\n",
    "        layout_xaxis_title=f'Predicted {name} score',\n",
    "        layout_yaxis_title='# of hits (area-normed)',\n",
    "        layout_yaxis_dtick=1,\n",
    "        layout_yaxis_type='log',\n",
    "        layout_legend_yanchor='top',\n",
    "        layout_legend_y=0.9,\n",
    "        layout_legend_xanchor='center',\n",
    "        layout_legend_x=0.5,\n",
    "        **style\n",
    "    )\n",
    "\n",
    "    for i, label in enumerate(nudata.semantic_classes):\n",
    "        fig.add_scatter(x=bin_centers, y=y[i], name=label, line_shape='spline')\n",
    "\n",
    "    fig.write_image(f'plots/score-{name}.pdf')\n",
    "    fig.write_image(f'plots/score-{name}.png')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da7220-d4c2-42ef-bfd6-0d28a76e46a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
